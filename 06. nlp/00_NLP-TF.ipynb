{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file):\n",
    "    for l in open(file,'r'):\n",
    "        yield json.loads(l)\n",
    "        \n",
    "datastore = list(parse_data('Sarcasm_Headlines_Dataset.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "labels = []\n",
    "urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in datastore:\n",
    "    sentences.append(item['headline'])\n",
    "    labels.append(item['is_sarcastic'])\n",
    "    urls.append(item['article_link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
       " \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\",\n",
       " \"mom starting to fear son's web series closest thing she will have to grandchild\",\n",
       " 'boehner just wants wife to listen, not come up with alternative debt-reduction ideas',\n",
       " 'j.k. rowling wishes snape happy birthday in the most magical way',\n",
       " \"advancing the world's women\",\n",
       " 'the fascinating case for eating lab-grown meat',\n",
       " 'this ceo will send your kids to school, if you work for his company',\n",
       " 'top snake handler leaves sinking huckabee campaign',\n",
       " \"friday's morning email: inside trump's presser for the ages\"]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0, 0, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5',\n",
       " 'https://www.huffingtonpost.com/entry/roseanne-revival-review_us_5ab3a497e4b054d118e04365',\n",
       " 'https://local.theonion.com/mom-starting-to-fear-son-s-web-series-closest-thing-she-1819576697',\n",
       " 'https://politics.theonion.com/boehner-just-wants-wife-to-listen-not-come-up-with-alt-1819574302',\n",
       " 'https://www.huffingtonpost.com/entry/jk-rowling-wishes-snape-happy-birthday_us_569117c4e4b0cad15e64fdcb',\n",
       " 'https://www.huffingtonpost.com/entry/advancing-the-worlds-women_b_6810038.html',\n",
       " 'https://www.huffingtonpost.com/entry/how-meat-is-grown-in-a-lab_us_561d1189e4b0c5a1ce607e86',\n",
       " 'https://www.huffingtonpost.com/entry/boxed-college-tuition-ben_n_7445644.html',\n",
       " 'https://politics.theonion.com/top-snake-handler-leaves-sinking-huckabee-campaign-1819578231',\n",
       " 'https://www.huffingtonpost.com/entry/fridays-morning-email-inside-trumps-presser-for-the-ages_us_58a6e33ee4b07602ad53a315']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'I love my dog',\n",
    "    'I love my cat',\n",
    "    'You love my dog!',\n",
    "    'Do you think my dog is amazing?'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Does a Tokenizer Do?\n",
    "1. Fitting on Text Data\n",
    "    - The tokenizer is fitted on a corpus of text, meaning it processes all the words in the dataset and creates a vocabulary (a mapping of words to unique integer indices).\n",
    "    - For example, if your text data contains sentences like \"I love programming\" and \"Programming is fun,\" the tokenizer builds a dictionary of all unique words: {'I': 1, 'love': 2, 'programming': 3, 'is': 4, 'fun': 5}.\n",
    "2. Text to integer conversion\n",
    "    - The tokenizer converts each word in the text data to its corresponding integer index.\n",
    "    - For example, the sentence \"I love programming\" is converted to [1, 2, 3].\n",
    "3. Handling Out-of-Vocabulary Words\n",
    "    - The tokenizer can be configured to handle out-of-vocabulary words in different ways. For example, it can replace them with a special token like `<UNK>` or ignore them altogether.\n",
    "    - in this case we use `<OOV>`\n",
    "4. Optional Preprocessing\n",
    "    - The tokenizer can be configured to preprocess the text data in different ways, such as converting all words to lowercase or removing punctuation.\n",
    "5. Padding Sequences\n",
    "    - The tokenizer can be configured to pad sequences to a fixed length, which is useful when training neural networks that require inputs of the same length.\n",
    "    - For example, if the maximum sequence length is set to 5, the sentence \"I love programming\" is padded to [1, 2, 3, 0, 0].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " 'my': 2,\n",
       " 'love': 3,\n",
       " 'dog': 4,\n",
       " 'i': 5,\n",
       " 'you': 6,\n",
       " 'cat': 7,\n",
       " 'do': 8,\n",
       " 'think': 9,\n",
       " 'is': 10,\n",
       " 'amazing': 11}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 3, 2, 4], [5, 3, 2, 7], [6, 3, 2, 4], [8, 6, 9, 2, 4, 10, 11]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  3,  2,  4,  0,  0,  0],\n",
       "       [ 5,  3,  2,  7,  0,  0,  0],\n",
       "       [ 6,  3,  2,  4,  0,  0,  0],\n",
       "       [ 8,  6,  9,  2,  4, 10, 11]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences = pad_sequences(sequences, padding=\"post\", truncating=\"post\")\n",
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    'i really love my dogs',\n",
    "    'my dog loves my mushrooms'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 1, 3, 2, 1], [2, 4, 1, 2, 1]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq = tokenizer.texts_to_sequences(test_data)\n",
    "test_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 1, 3, 2, 1, 0, 0, 0, 0, 0],\n",
       "       [2, 4, 1, 2, 1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_test_seq = pad_sequences(test_seq, padding=\"post\", maxlen=10)\n",
    "padded_test_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
